{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f66b9a-19b8-4987-98a0-27af1d8dd4a0",
   "metadata": {},
   "source": [
    "# 손동작 분류 경진대회"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7882a81b-5309-4fa3-9b39-c909d0f284f8",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e3b12ea-dd29-4a89-ba1b-83660af4c424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6628a40-a2e5-4eba-8087-6b40a3d75265",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0676658-cbec-46d2-9e5c-084e71aa0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Jaesu/Dacon-Basic/손동작-분류/Data/train.csv')\n",
    "test = pd.read_csv('C:/Users/Jaesu/Dacon-Basic/손동작-분류/Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7dc38a-f08e-4aa8-88f8-6430c8ee142c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2335, 34), (9343, 33))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e921612a-3375-47e2-a9a2-e49c249ad3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id', axis=1, inplace=True) ## id 컬럼 드랍\n",
    "test.drop('id', axis=1, inplace=True) ## id 컬럼 드랍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea2d07f-c358-4ed4-8538-ea58b224d82d",
   "metadata": {},
   "source": [
    "## 센서 데이터를 이미지로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01631bd5-66fe-4b6d-8cf0-9b022fe99e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_27</th>\n",
       "      <th>sensor_28</th>\n",
       "      <th>sensor_29</th>\n",
       "      <th>sensor_30</th>\n",
       "      <th>sensor_31</th>\n",
       "      <th>sensor_32</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2335.000000</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>2335.000000</td>\n",
       "      <td>2335.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.122174</td>\n",
       "      <td>-1.024673</td>\n",
       "      <td>-0.672769</td>\n",
       "      <td>-0.147724</td>\n",
       "      <td>-0.327494</td>\n",
       "      <td>-0.423462</td>\n",
       "      <td>0.676275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081374</td>\n",
       "      <td>-0.370812</td>\n",
       "      <td>-0.726941</td>\n",
       "      <td>-0.809534</td>\n",
       "      <td>-0.495062</td>\n",
       "      <td>-0.743585</td>\n",
       "      <td>1.523340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.486353</td>\n",
       "      <td>7.399859</td>\n",
       "      <td>26.519159</td>\n",
       "      <td>15.551500</td>\n",
       "      <td>11.461970</td>\n",
       "      <td>7.314322</td>\n",
       "      <td>26.869479</td>\n",
       "      <td>...</td>\n",
       "      <td>25.923355</td>\n",
       "      <td>15.541803</td>\n",
       "      <td>11.636507</td>\n",
       "      <td>7.469744</td>\n",
       "      <td>25.291238</td>\n",
       "      <td>16.300385</td>\n",
       "      <td>1.118221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-94.746969</td>\n",
       "      <td>-63.942094</td>\n",
       "      <td>-122.195138</td>\n",
       "      <td>-111.870691</td>\n",
       "      <td>-94.147972</td>\n",
       "      <td>-70.916786</td>\n",
       "      <td>-105.956553</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.751637</td>\n",
       "      <td>-105.890010</td>\n",
       "      <td>-74.977182</td>\n",
       "      <td>-74.006065</td>\n",
       "      <td>-121.097086</td>\n",
       "      <td>-123.876153</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.036597</td>\n",
       "      <td>-4.031957</td>\n",
       "      <td>-14.878500</td>\n",
       "      <td>-7.116633</td>\n",
       "      <td>-3.968687</td>\n",
       "      <td>-3.957699</td>\n",
       "      <td>-13.937806</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.096840</td>\n",
       "      <td>-8.004561</td>\n",
       "      <td>-3.981055</td>\n",
       "      <td>-3.988965</td>\n",
       "      <td>-13.998874</td>\n",
       "      <td>-7.873898</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.951398</td>\n",
       "      <td>-1.015582</td>\n",
       "      <td>-0.961088</td>\n",
       "      <td>-0.890469</td>\n",
       "      <td>-0.871690</td>\n",
       "      <td>-0.804810</td>\n",
       "      <td>0.058910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.954791</td>\n",
       "      <td>-0.989293</td>\n",
       "      <td>-0.889780</td>\n",
       "      <td>-0.928504</td>\n",
       "      <td>-0.955684</td>\n",
       "      <td>-1.019547</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.895540</td>\n",
       "      <td>2.140456</td>\n",
       "      <td>13.974075</td>\n",
       "      <td>6.110973</td>\n",
       "      <td>2.970387</td>\n",
       "      <td>3.006144</td>\n",
       "      <td>13.934438</td>\n",
       "      <td>...</td>\n",
       "      <td>13.903783</td>\n",
       "      <td>5.922250</td>\n",
       "      <td>2.972719</td>\n",
       "      <td>2.519426</td>\n",
       "      <td>13.926128</td>\n",
       "      <td>5.121679</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68.876142</td>\n",
       "      <td>39.913391</td>\n",
       "      <td>127.124171</td>\n",
       "      <td>102.015561</td>\n",
       "      <td>89.059852</td>\n",
       "      <td>34.923040</td>\n",
       "      <td>120.046277</td>\n",
       "      <td>...</td>\n",
       "      <td>123.179253</td>\n",
       "      <td>111.137925</td>\n",
       "      <td>54.098746</td>\n",
       "      <td>35.896503</td>\n",
       "      <td>125.974107</td>\n",
       "      <td>104.959621</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sensor_1     sensor_2     sensor_3     sensor_4     sensor_5  \\\n",
       "count  2335.000000  2335.000000  2335.000000  2335.000000  2335.000000   \n",
       "mean     -1.122174    -1.024673    -0.672769    -0.147724    -0.327494   \n",
       "std      11.486353     7.399859    26.519159    15.551500    11.461970   \n",
       "min     -94.746969   -63.942094  -122.195138  -111.870691   -94.147972   \n",
       "25%      -4.036597    -4.031957   -14.878500    -7.116633    -3.968687   \n",
       "50%      -0.951398    -1.015582    -0.961088    -0.890469    -0.871690   \n",
       "75%       2.895540     2.140456    13.974075     6.110973     2.970387   \n",
       "max      68.876142    39.913391   127.124171   102.015561    89.059852   \n",
       "\n",
       "          sensor_6     sensor_7  ...    sensor_27    sensor_28    sensor_29  \\\n",
       "count  2335.000000  2335.000000  ...  2335.000000  2335.000000  2335.000000   \n",
       "mean     -0.423462     0.676275  ...    -0.081374    -0.370812    -0.726941   \n",
       "std       7.314322    26.869479  ...    25.923355    15.541803    11.636507   \n",
       "min     -70.916786  -105.956553  ...  -105.751637  -105.890010   -74.977182   \n",
       "25%      -3.957699   -13.937806  ...   -14.096840    -8.004561    -3.981055   \n",
       "50%      -0.804810     0.058910  ...    -0.954791    -0.989293    -0.889780   \n",
       "75%       3.006144    13.934438  ...    13.903783     5.922250     2.972719   \n",
       "max      34.923040   120.046277  ...   123.179253   111.137925    54.098746   \n",
       "\n",
       "         sensor_30    sensor_31    sensor_32       target  \n",
       "count  2335.000000  2335.000000  2335.000000  2335.000000  \n",
       "mean     -0.809534    -0.495062    -0.743585     1.523340  \n",
       "std       7.469744    25.291238    16.300385     1.118221  \n",
       "min     -74.006065  -121.097086  -123.876153     0.000000  \n",
       "25%      -3.988965   -13.998874    -7.873898     1.000000  \n",
       "50%      -0.928504    -0.955684    -1.019547     2.000000  \n",
       "75%       2.519426    13.926128     5.121679     3.000000  \n",
       "max      35.896503   125.974107   104.959621     3.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1975db-76e9-4c8f-9800-3cbaff805029",
   "metadata": {},
   "source": [
    "`-` 32개의 센서피쳐는 하나의 픽셀을 의미하는 것이 아닐까?(손동작 이미지를 32개의 픽셀로 나눈 것 같다; 아님말고)\n",
    "\n",
    "`-` 0부근에 값이 많고 변수마다 분포가 유사함(종모양) \n",
    "\n",
    "`-` $8\\times 4$ 배열로 변환하고 이를 확인해보자($4\\times 8$로 해도 상관없을 듯)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a5432a-e538-4351-96a9-db3236af90aa",
   "metadata": {},
   "source": [
    "`-` 위는 각 target의 sensor_1부터 sensor_32까지 각각의 평균이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a679cc7-5ba0-4922-afbe-ec2b800bf422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 10))\n",
    "for i in range(4) :\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.title(f'target{i}')\n",
    "    plt.imshow(df.groupby('target').agg('mean').iloc[i,:].to_numpy().reshape(8, 4))\n",
    "plt.suptitle('Target image', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e4a840-8d86-4ae7-8aa1-9f72d681466f",
   "metadata": {},
   "source": [
    "`-` 위의 4가지 그림을 보면 target마다 평균적으로 값의 차이가 있음을 알 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c2f807-d656-4cd0-9599-a246ebf1c8b1",
   "metadata": {},
   "source": [
    "## CNN 설계 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7314dd5e-9a0a-43c5-a8e8-4cf1fa315375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5058368-cf4c-4860-a3e1-c5fbf1e7707a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20fbecdce90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(22) ## 재현을 위한 seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfac14-a75c-4851-b317-08dc44ab3920",
   "metadata": {},
   "source": [
    "`-` 일단 데이터를 정규화시켜주자(0부터 1까지)\n",
    "\n",
    "`-` 값이 음수이면 활성화함수로 렐루를 취할 때 0이 되면서 노드가 죽어버린다(기울기 소멸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "003c841f-9696-420a-b736-39c8d75462a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['target']\n",
    "df.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be952f6b-3120-4e0a-8eca-2bda7d250258",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = (df + 130) / 260 ## 음수를 양수로 만들어주고 값을 0~1사이로 맞춰준다\n",
    "X_test = (test + 130) / 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d7bc061-623d-485d-8a17-191b1f900f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = torch.tensor(np.array(X_df).reshape(-1, 1, 8, 4), dtype=torch.float32) ## 1(흑백) * 8(높이) * 4(너비) 이미지가 -1(2335)개 존재함\n",
    "X_test = torch.tensor(np.array(X_test).reshape(-1, 1, 8, 4), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58957b68-7441-4568-b873-134f985860a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : tensor(0.0085) \n",
      "max : tensor(0.9891)\n"
     ]
    }
   ],
   "source": [
    "print('min :', X_df.min(), '\\nmax :', X_df.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a22eec-9411-4c71-a3b8-cbb9b5787767",
   "metadata": {},
   "source": [
    "`-` 정규화가 잘 되었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d23afade-5aab-476d-95ff-d0d377cee2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2335"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13b79f0e-397f-4d3e-ace6-0742b95b367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(2, 1), padding='same'), ## padding='same' 옵션을 사용할려면 stride가 1이어야 한다\n",
    "            ## 흑백이미지이므로 처음 인풋 채널은 1이다\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 2), padding='same'), ## 이미지가 직사각형(8*4) 모양이라 직사각형 커널 사용\n",
    "            nn.ReLU(),\n",
    "            #nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2)), ## 이미지 크기가 작으니 Pooling은 하지 않음\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 16, kernel_size=(2, 1), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 2), padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.AdaptiveAvgPool2d(1) ## Flatten역할 ## 이미지를 평균내서 1*1 크기로 만든다\n",
    "        )\n",
    "        \n",
    "        self.linear_model = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 4) ## softmax는 옵티마이저(CrossEntorpyLoss)에서 수행\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_model(x) ## shape: (N, 1, 8, 4) -> (N, 32, 1, 1) \n",
    "        x = x.squeeze() ## shape: (N, 32, 1, 1) -> (N, 32)\n",
    "        x = self.linear_model(x) ## shape: (N, 32) -> (N, 4)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ad78b3e-3384-4dfe-85af-5cb6831ef859",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear layer 가중치 초기화\n",
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "539ff5dc-cb25-4d82-8961-d4112d18ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## accuracy 계산\n",
    "def accuracy(true, pred):\n",
    "    return sum(true == pred) / len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "744e13f5-b162-40ac-a3b0-d356c249e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    ## 코드 참고: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "    \n",
    "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='./weight', n_fold=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
    "                            Default: 7\n",
    "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
    "                            Default: False\n",
    "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
    "                            Default: 0\n",
    "            path (str): checkpoint저장 경로\n",
    "                            Default: 'checkpoint.pt'\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.val_acc = None\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.n_fold = n_fold\n",
    "\n",
    "    def __call__(self, val_loss, val_acc, model):\n",
    "\n",
    "        score = -val_loss ## val_loss는 작을수록 좋다 ## score는 0에 가까울수록 좋다\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, val_acc, model)  \n",
    "        elif score < self.best_score + self.delta: ## loss가 개선되지 않았을 때\n",
    "            self.counter += 1 ## 카운팅 +1\n",
    "            # print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience: ## 만약 loss가 개선되지 않은 스탭이 patience보다 크거나 같아진다면 조기중단\n",
    "                self.early_stop = True\n",
    "        else: ## loss가 개선됨\n",
    "            self.best_score = score ## score 갱신\n",
    "            self.save_checkpoint(val_loss, val_acc, model) ## loss와 model 저장\n",
    "            self.counter = 0 ## loss가 개선되었으므로 0으로 초기화\n",
    "\n",
    "    def save_checkpoint(self, val_loss, val_acc, model):\n",
    "        \"\"\"validation loss가 감소하면 모델을 저장\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.5f} -> {val_loss:.5f})  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path + f'/best_{self.n_fold}.pt')\n",
    "        self.val_loss_min = val_loss ## 모델이 더 좋게 갱신되었으므로 이때의 valid loss를 기준치로 저장\n",
    "        self.val_acc = val_acc ## 이때의 valid accuracy도 저장해준다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79b14dc-fdcc-49a5-a167-f9bdc6c13e0f",
   "metadata": {},
   "source": [
    "`-` 모델 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebb48f30-b94d-4423-8e2d-e377a4a67f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold = StratifiedKFold(n_splits=15, random_state=22, shuffle=True) ## 15겹 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a11a917d-d153-4321-910c-bf9c6ed1f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'C:/Users/Jaesu/github_desktop/Dacon-Basic/손동작-분류/손동작-분류-모델링/weight'\n",
    "learning_rate = 0.005\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "loss_fn = torch.nn.CrossEntropyLoss()   ## 손실 함수에 소프트맥스 함수 포함 -> net 내부에서 마지막 활성화함수로 소프트맥스 사용안해도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a045234-3251-42a2-a879-8e0f8b66ca63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1752  valid loss = 0.78645\n",
      "[Epoch:  21] train loss = 0.2075  valid loss = 0.4209\n",
      "[Epoch:  23] train loss = 0.1853  valid loss = 0.45038\n",
      "Early stopping!\n",
      "1 Fold -> Best Valid Loss: 0.37015  Best Valid Accuracy: 0.86538\n",
      "\n",
      "\n",
      "2 Fold Training......\n",
      "[Epoch:   1] train loss = 1.179  valid loss = 1.35\n",
      "[Epoch:  21] train loss = 0.25006  valid loss = 0.40409\n",
      "[Epoch:  26] train loss = 0.15745  valid loss = 0.4094\n",
      "Early stopping!\n",
      "2 Fold -> Best Valid Loss: 0.38648  Best Valid Accuracy: 0.85897\n",
      "\n",
      "\n",
      "3 Fold Training......\n",
      "[Epoch:   1] train loss = 1.2226  valid loss = 0.9251\n",
      "[Epoch:  21] train loss = 0.1331  valid loss = 0.53985\n",
      "[Epoch:  29] train loss = 0.059399  valid loss = 0.55884\n",
      "Early stopping!\n",
      "3 Fold -> Best Valid Loss: 0.48124  Best Valid Accuracy: 0.85256\n",
      "\n",
      "\n",
      "4 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1188  valid loss = 1.1323\n",
      "[Epoch:  21] train loss = 0.17499  valid loss = 0.60583\n",
      "[Epoch:  23] train loss = 0.13669  valid loss = 0.67554\n",
      "Early stopping!\n",
      "4 Fold -> Best Valid Loss: 0.47020  Best Valid Accuracy: 0.85256\n",
      "\n",
      "\n",
      "5 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1038  valid loss = 0.7738\n",
      "[Epoch:  21] train loss = 0.18257  valid loss = 0.32346\n",
      "[Epoch:  32] train loss = 0.066289  valid loss = 0.31708\n",
      "Early stopping!\n",
      "5 Fold -> Best Valid Loss: 0.25131  Best Valid Accuracy: 0.88462\n",
      "\n",
      "\n",
      "6 Fold Training......\n",
      "[Epoch:   1] train loss = 1.336  valid loss = 1.0773\n",
      "[Epoch:  21] train loss = 0.2233  valid loss = 0.54517\n",
      "[Epoch:  31] train loss = 0.12511  valid loss = 0.65098\n",
      "Early stopping!\n",
      "6 Fold -> Best Valid Loss: 0.54517  Best Valid Accuracy: 0.84615\n",
      "\n",
      "\n",
      "7 Fold Training......\n",
      "[Epoch:   1] train loss = 1.3176  valid loss = 0.94464\n",
      "[Epoch:  21] train loss = 0.14917  valid loss = 0.4917\n",
      "[Epoch:  29] train loss = 0.08096  valid loss = 0.50624\n",
      "Early stopping!\n",
      "7 Fold -> Best Valid Loss: 0.40909  Best Valid Accuracy: 0.85897\n",
      "\n",
      "\n",
      "8 Fold Training......\n",
      "[Epoch:   1] train loss = 0.94853  valid loss = 1.2497\n",
      "[Epoch:  21] train loss = 0.24797  valid loss = 0.55391\n",
      "[Epoch:  22] train loss = 0.23646  valid loss = 0.50074\n",
      "Early stopping!\n",
      "8 Fold -> Best Valid Loss: 0.45334  Best Valid Accuracy: 0.78205\n",
      "\n",
      "\n",
      "9 Fold Training......\n",
      "[Epoch:   1] train loss = 1.067  valid loss = 1.0606\n",
      "[Epoch:  21] train loss = 0.15021  valid loss = 0.50442\n",
      "Early stopping!\n",
      "9 Fold -> Best Valid Loss: 0.36046  Best Valid Accuracy: 0.89103\n",
      "\n",
      "\n",
      "10 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1621  valid loss = 0.88979\n",
      "[Epoch:  21] train loss = 0.21672  valid loss = 0.61092\n",
      "[Epoch:  33] train loss = 0.088631  valid loss = 0.7215\n",
      "Early stopping!\n",
      "10 Fold -> Best Valid Loss: 0.47912  Best Valid Accuracy: 0.85256\n",
      "\n",
      "\n",
      "11 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1072  valid loss = 0.86644\n",
      "[Epoch:  21] train loss = 0.22058  valid loss = 0.45039\n",
      "[Epoch:  33] train loss = 0.1017  valid loss = 0.51525\n",
      "Early stopping!\n",
      "11 Fold -> Best Valid Loss: 0.38923  Best Valid Accuracy: 0.88387\n",
      "\n",
      "\n",
      "12 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1059  valid loss = 2.6054\n",
      "[Epoch:  21] train loss = 0.19666  valid loss = 0.46583\n",
      "[Epoch:  24] train loss = 0.15616  valid loss = 0.44483\n",
      "Early stopping!\n",
      "12 Fold -> Best Valid Loss: 0.43168  Best Valid Accuracy: 0.87097\n",
      "\n",
      "\n",
      "13 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1083  valid loss = 0.80606\n",
      "[Epoch:  21] train loss = 0.15719  valid loss = 0.49755\n",
      "[Epoch:  23] train loss = 0.13957  valid loss = 0.62345\n",
      "Early stopping!\n",
      "13 Fold -> Best Valid Loss: 0.39796  Best Valid Accuracy: 0.85161\n",
      "\n",
      "\n",
      "14 Fold Training......\n",
      "[Epoch:   1] train loss = 1.0624  valid loss = 0.87348\n",
      "[Epoch:  21] train loss = 0.17451  valid loss = 0.35464\n",
      "[Epoch:  27] train loss = 0.1172  valid loss = 0.40204\n",
      "Early stopping!\n",
      "14 Fold -> Best Valid Loss: 0.31554  Best Valid Accuracy: 0.87742\n",
      "\n",
      "\n",
      "15 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1618  valid loss = 0.89559\n",
      "[Epoch:  21] train loss = 0.17077  valid loss = 0.55002\n",
      "[Epoch:  38] train loss = 0.029957  valid loss = 0.57905\n",
      "Early stopping!\n",
      "15 Fold -> Best Valid Loss: 0.44087  Best Valid Accuracy: 0.84516\n",
      "\n",
      "\n",
      "15Fold Mean Valid Accuracy: 0.85826\n",
      "15Fold Mean Valid Loss: 0.41212\n"
     ]
    }
   ],
   "source": [
    "## AVG_Pooling X\n",
    "cnn_acc = [] ## fold별 valid셋의 평균 정확도\n",
    "cnn_loss = [] ## fold별 valid셋의 평균 손실\n",
    "n_fold = 0 ## 몇 번째 fold인지 check\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(skfold.split(X_df, target)):\n",
    "    print(f'{i + 1} Fold Training......')\n",
    "    X_train, y_train = X_df[train_idx], target[train_idx]\n",
    "    X_valid, y_valid = X_df[valid_idx], target[valid_idx]\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.int64) ## target을 텐서로 변환\n",
    "    y_valid = torch.tensor(y_valid.to_numpy(), dtype=torch.int64) ## target을 텐서로 변환\n",
    "    \n",
    "    ## early stopping\n",
    "    n_fold += 1\n",
    "    early_stopping = EarlyStopping(patience=10,\n",
    "                                     verbose=False,\n",
    "                                     path=save_path,\n",
    "                                     n_fold=n_fold) ## 10번의 에폭후에도 valid loss가 작아지지 않으면 조기 중단\n",
    "    \n",
    "    ## CNN 모델\n",
    "    net = CNN()\n",
    "    net.apply(init_weights) ## Linear layer 가중치 초기화\n",
    "    \n",
    "    ## Dataset, Dataloader\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    valid_dataset = TensorDataset(X_valid, y_valid)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    train_total_batch = len(train_dataloader) ## 배치 크기\n",
    "    valid_total_batch = len(valid_dataloader)\n",
    "    \n",
    "    ## optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate) ## 옵티마이저에 최적화할 파라미터와 학습률 전달\n",
    "    \n",
    "    ## scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                                lr_lambda=lambda epoch: 0.95 ** epoch,\n",
    "                                                last_epoch=-1,\n",
    "                                                verbose=False)\n",
    "    \n",
    "    ## fold별로 모델 학습\n",
    "    net.train() ## 훈련모드\n",
    "    for epoch in range(epochs): ## (배치사이즈 * 에폭)만큼 훈련시킴\n",
    "        train_avg_loss, valid_avg_loss, valid_avg_acc = 0, 0, 0 ## 에폭별 배치단위 평균 훈련 오차와 평균 평가 오차와 valid accuracy\n",
    "\n",
    "        for X, y in train_dataloader: ## 미니 배치 단위로 꺼내온다, X는 미니 배치, y는 레이블\n",
    "            optimizer.zero_grad() ## 그래디언트 초기화\n",
    "            yhat = net(X) ## y_hat을 구한다\n",
    "            loss = loss_fn(yhat, y) ## 오차를 계산 ## train loss\n",
    "            loss.backward()  ## 미분\n",
    "            optimizer.step() ## 업데이트\n",
    "            train_avg_loss += (loss / train_total_batch) ## 각 배치마다 훈련 오차 누적\n",
    "    \n",
    "        ## epoch마다 학습률 조절\n",
    "        scheduler.step()\n",
    "    \n",
    "        ## epoch마다 모델 평가\n",
    "        net.eval() ## 평가모드\n",
    "        for X, y in valid_dataloader: \n",
    "            with torch.no_grad(): ## 평가할 땐 역전파를 쓸 필요가 없으니까\n",
    "                yhat = net(X)\n",
    "                loss = loss_fn(yhat, y) ## valid loss\n",
    "                acc = accuracy(y.detach().numpy(), yhat.detach().numpy().argmax(-1))       \n",
    "                valid_avg_acc += (acc * len(y) / len(valid_dataset)) ## 각 배치마다 정확도(정답 개수 / 전체 개수)\n",
    "                valid_avg_loss += loss / valid_total_batch ## 각 배치마다 평가 오차 누적                                                                  \n",
    "\n",
    "        if epoch % 20 == 0 or epoch == epochs - 1: \n",
    "            ## 20의 배수값을 가지는 에폭마다 평균 배치 훈련 오차와 평가 오차 출력\n",
    "            print('[Epoch: {:>3}] train loss = {:>.5}  valid loss = {:>.5}'.format(epoch + 1, train_avg_loss, valid_avg_loss)) \n",
    "            \n",
    "        ## epoch마다 early stopping 실행\n",
    "        early_stopping(valid_avg_loss, valid_avg_acc, net) ## __call__ function\n",
    "        if early_stopping.early_stop: ## early_stop이 true이면\n",
    "            if epoch % 20 != 0 and epoch != epochs - 1:\n",
    "                print('[Epoch: {:>3}] train loss = {:>.5}  valid loss = {:>.5}'.format(epoch + 1, train_avg_loss, valid_avg_loss)) \n",
    "            print('Early stopping!')\n",
    "            break \n",
    "\n",
    "    cnn_acc.append(early_stopping.val_acc) ## fold별 loss가 가장 작은 모델의 정확도\n",
    "    cnn_loss.append(early_stopping.val_loss_min) ## fold별 loss가 가장 작은 모델의 손실\n",
    "    \n",
    "    ## fold별 평가 루프 종료시 가장 작은 loss와 이때의 accuracy를 출력\n",
    "    print(f'{i + 1} Fold -> Best Valid Loss: {early_stopping.val_loss_min:.5f}  Best Valid Accuracy: {early_stopping.val_acc:.5f}\\n\\n')\n",
    "    \n",
    "## 폴드별 가장 loss가 작은 모델들의 평균 정확도와 평균 손실\n",
    "print(f'{skfold.n_splits}Fold Mean Valid Accuracy: {np.mean(cnn_acc):.5f}')\n",
    "print(f'{skfold.n_splits}Fold Mean Valid Loss: {np.mean(cnn_loss):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6103a10f-9d63-4dea-bb9b-71664d823c07",
   "metadata": {},
   "source": [
    "### test 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22281f79-a43f-40b0-baeb-23ef225f86ad",
   "metadata": {},
   "source": [
    "`-` softmax function을 취하면 4개의 원소 중 최대값의 인덱스 번호가 최종 예측값이 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9f4b9a4-43e3-4852-95a6-fea28e662691",
   "metadata": {},
   "outputs": [],
   "source": [
    "weigh_path_list = glob(save_path + '/*.pt')\n",
    "cnn_pred = torch.tensor(np.zeros((X_test.shape[0], 4))) ## test예측값\n",
    "\n",
    "for weight in weigh_path_list :\n",
    "    net.load_state_dict(torch.load(weight))\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = net(X_test) ## shape -> (9343, 4)\n",
    "        cnn_pred += outputs / 14  \n",
    "        \n",
    "_, pred = torch.max(cnn_pred, dim=1) ## 최대값과 인덱스를 반환\n",
    "## return (value, indices), 1차원을 기준으로 max를 구한다\n",
    "## 1차원을 기준으로 max를 구하므로 1차원을 없앤 9343개의 max가 반환된다\n",
    "## 행별로 4개의 값 중 최대값을 리턴(총 9343개)\n",
    "## 만약 dim=0으로 했다면 0번째 열~4번째 열별로 최대값을 구하므로 총 4개의 max값이 리턴됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0ff1a95-e6e3-406c-87c6-258837380de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('C:/Users/Jaesu/Dacon-Basic/손동작-분류/Data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "def9e81f-bfac-40a1-a4f5-b97dffccca50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   1       0\n",
       "1   2       0\n",
       "2   3       1\n",
       "3   4       3\n",
       "4   5       2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['target'] = pred\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b544fa77-6526-436f-9ec2-715ebdff3179",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('C:/Users/Jaesu/github_desktop/Dacon-Basic/손동작-분류/Data/submission5_15fold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c226f7ea-19f2-49d9-926f-909fc42cc8c2",
   "metadata": {},
   "source": [
    "## 센서 데이터 3D로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e688da-4630-4ef1-acf6-e3cb433d2c61",
   "metadata": {},
   "source": [
    "`-` 센서 데이터는 손동작을 기록한 것이니까 3차원이지 않을까?(손은 3차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dba7c92-9560-4893-86c7-ea9532ad3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = (df + 130) / 260 ## 음수를 양수로 만들어주고 값을 0~1사이로 맞춰준다\n",
    "X_test = (test + 130) / 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82cb9da2-a82f-477b-985f-3969ce1ede51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = torch.tensor(np.array(X_df).reshape(-1, 1, 2, 4, 4), dtype=torch.float32) ## 1(흑백) * 2(깊이) * 4(세로) * 4(가로) 이미지가 -1(2335)개 존재함\n",
    "X_test = torch.tensor(np.array(X_test).reshape(-1, 1, 2, 4, 4), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "054c91c6-e08e-4c82-b1c0-042738031488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : tensor(0.0085) \n",
      "max : tensor(0.9891)\n"
     ]
    }
   ],
   "source": [
    "print('min :', X_df.min(), '\\nmax :', X_df.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e738d0e-ba98-4eb7-a001-1c71524feeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3D(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_model = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=1, out_channels=8, kernel_size=(1, 1, 1), padding='same'), ## padding='same' 옵션을 사용할려면 stride가 1이어야 한다\n",
    "            ## 흑백 3d 데이터이므로 처음 인풋 채널은 1이다\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.Conv3d(8, 16, kernel_size=(1, 2, 2), padding='same'), ## 센서가 직육면체 모양이여서 직육면체 커널을 사용\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.Conv3d(16, 16, kernel_size=(2, 1, 1), padding='same'), ## 센서크기가 작아 커널 사이즈도 작은 것 사용\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.Conv3d(16, 8, kernel_size=(2, 1, 1), padding='same'),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.Conv3d(8, 16, kernel_size=(2, 2, 2), padding='same'),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.AdaptiveAvgPool3d(1) ## Flatten역할 ## 3d 센서 데이터값를 평균내서 1*1*1 크기로 만든다\n",
    "        )\n",
    "        \n",
    "        self.linear_model = nn.Sequential(\n",
    "            nn.Linear(16, 4) ## softmax는 옵티마이저(CrossEntorpyLoss)에서 수행\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_model(x) ## shape: (N, 1, 2, 4, 4) -> (N, 16, 1, 1, 1) \n",
    "        x = x.view(-1, 16) ## shape: (N, 16, 1, 1, 1) -> (N, 16)\n",
    "        x = self.linear_model(x) ## shape: (N, 16) -> (N, 4)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c84edae-1701-43d5-a533-27c356bb0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold = StratifiedKFold(n_splits=15, random_state=22, shuffle=True) ## 15겹 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3bac0a59-3d6f-4a37-8fa0-be41e8151cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'C:/Users/Jaesu/github_desktop/Dacon-Basic/손동작-분류/손동작-분류-모델링/weight'\n",
    "learning_rate = 0.004\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "loss_fn = torch.nn.CrossEntropyLoss()   ## 손실 함수에 소프트맥스 함수 포함 -> net 내부에서 마지막 활성화함수로 소프트맥스 사용안해도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5a9dd1fe-3cfd-4159-ae85-d97215b93e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Fold Training......\n",
      "[Epoch:   1] train loss = 1.2301  valid loss = 1.3786\n",
      "[Epoch:  21] train loss = 0.30206  valid loss = 0.46183\n",
      "Early stopping!\n",
      "1 Fold -> Best Valid Loss: 0.38337  Best Valid Accuracy: 0.83974\n",
      "\n",
      "\n",
      "2 Fold Training......\n",
      "[Epoch:   1] train loss = 1.0408  valid loss = 1.4324\n",
      "[Epoch:  21] train loss = 0.32445  valid loss = 0.36753\n",
      "[Epoch:  34] train loss = 0.24812  valid loss = 0.39354\n",
      "Early stopping!\n",
      "2 Fold -> Best Valid Loss: 0.35964  Best Valid Accuracy: 0.85256\n",
      "\n",
      "\n",
      "3 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1717  valid loss = 1.2547\n",
      "[Epoch:  19] train loss = 0.30232  valid loss = 0.45852\n",
      "Early stopping!\n",
      "3 Fold -> Best Valid Loss: 0.40105  Best Valid Accuracy: 0.85256\n",
      "\n",
      "\n",
      "4 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1589  valid loss = 1.0986\n",
      "[Epoch:  20] train loss = 0.28962  valid loss = 0.47615\n",
      "Early stopping!\n",
      "4 Fold -> Best Valid Loss: 0.45229  Best Valid Accuracy: 0.85256\n",
      "\n",
      "\n",
      "5 Fold Training......\n",
      "[Epoch:   1] train loss = 1.0769  valid loss = 1.0384\n",
      "[Epoch:  21] train loss = 0.29057  valid loss = 0.36025\n",
      "[Epoch:  22] train loss = 0.27451  valid loss = 0.30255\n",
      "Early stopping!\n",
      "5 Fold -> Best Valid Loss: 0.29442  Best Valid Accuracy: 0.90385\n",
      "\n",
      "\n",
      "6 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1129  valid loss = 1.008\n",
      "[Epoch:  21] train loss = 0.28607  valid loss = 0.46344\n",
      "[Epoch:  28] train loss = 0.24626  valid loss = 0.5685\n",
      "Early stopping!\n",
      "6 Fold -> Best Valid Loss: 0.46344  Best Valid Accuracy: 0.82051\n",
      "\n",
      "\n",
      "7 Fold Training......\n",
      "[Epoch:   1] train loss = 1.0615  valid loss = 0.91653\n",
      "[Epoch:  21] train loss = 0.28838  valid loss = 0.36676\n",
      "[Epoch:  28] train loss = 0.25006  valid loss = 0.40977\n",
      "Early stopping!\n",
      "7 Fold -> Best Valid Loss: 0.36676  Best Valid Accuracy: 0.88462\n",
      "\n",
      "\n",
      "8 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1654  valid loss = 1.0921\n",
      "[Epoch:  21] train loss = 0.30386  valid loss = 0.48492\n",
      "[Epoch:  23] train loss = 0.28287  valid loss = 0.50511\n",
      "Early stopping!\n",
      "8 Fold -> Best Valid Loss: 0.44825  Best Valid Accuracy: 0.80769\n",
      "\n",
      "\n",
      "9 Fold Training......\n",
      "[Epoch:   1] train loss = 1.2047  valid loss = 1.0708\n",
      "[Epoch:  21] train loss = 0.29135  valid loss = 0.34115\n",
      "[Epoch:  41] train loss = 0.17282  valid loss = 0.30109\n",
      "[Epoch:  43] train loss = 0.1638  valid loss = 0.30643\n",
      "Early stopping!\n",
      "9 Fold -> Best Valid Loss: 0.29774  Best Valid Accuracy: 0.88462\n",
      "\n",
      "\n",
      "10 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1612  valid loss = 1.5182\n",
      "[Epoch:  21] train loss = 0.31812  valid loss = 0.50998\n",
      "[Epoch:  29] train loss = 0.25551  valid loss = 0.57889\n",
      "Early stopping!\n",
      "10 Fold -> Best Valid Loss: 0.47890  Best Valid Accuracy: 0.82051\n",
      "\n",
      "\n",
      "11 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1192  valid loss = 1.7322\n",
      "[Epoch:  21] train loss = 0.30252  valid loss = 0.38897\n",
      "[Epoch:  22] train loss = 0.309  valid loss = 0.50807\n",
      "Early stopping!\n",
      "11 Fold -> Best Valid Loss: 0.38537  Best Valid Accuracy: 0.89677\n",
      "\n",
      "\n",
      "12 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1418  valid loss = 1.0734\n",
      "[Epoch:  20] train loss = 0.3144  valid loss = 0.4028\n",
      "Early stopping!\n",
      "12 Fold -> Best Valid Loss: 0.37135  Best Valid Accuracy: 0.86452\n",
      "\n",
      "\n",
      "13 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1202  valid loss = 1.2878\n",
      "[Epoch:  21] train loss = 0.30427  valid loss = 0.35191\n",
      "[Epoch:  26] train loss = 0.27373  valid loss = 0.33084\n",
      "Early stopping!\n",
      "13 Fold -> Best Valid Loss: 0.32144  Best Valid Accuracy: 0.85161\n",
      "\n",
      "\n",
      "14 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1605  valid loss = 1.6547\n",
      "[Epoch:  21] train loss = 0.28562  valid loss = 0.33332\n",
      "[Epoch:  24] train loss = 0.25811  valid loss = 0.37281\n",
      "Early stopping!\n",
      "14 Fold -> Best Valid Loss: 0.31341  Best Valid Accuracy: 0.87742\n",
      "\n",
      "\n",
      "15 Fold Training......\n",
      "[Epoch:   1] train loss = 1.1014  valid loss = 1.5483\n",
      "[Epoch:  21] train loss = 0.29515  valid loss = 0.54916\n",
      "Early stopping!\n",
      "15 Fold -> Best Valid Loss: 0.45177  Best Valid Accuracy: 0.81290\n",
      "\n",
      "\n",
      "15Fold Mean Valid Accuracy: 0.85483\n",
      "15Fold Mean Valid Loss: 0.38595\n"
     ]
    }
   ],
   "source": [
    "cnn_acc = [] ## fold별 valid셋의 평균 정확도\n",
    "cnn_loss = [] ## fold별 valid셋의 평균 손실\n",
    "n_fold = 0 ## 몇 번째 fold인지 check\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(skfold.split(X_df, target)):\n",
    "    print(f'{i + 1} Fold Training......')\n",
    "    X_train, y_train = X_df[train_idx], target[train_idx]\n",
    "    X_valid, y_valid = X_df[valid_idx], target[valid_idx]\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.int64) ## target을 텐서로 변환\n",
    "    y_valid = torch.tensor(y_valid.to_numpy(), dtype=torch.int64) ## target을 텐서로 변환\n",
    "    \n",
    "    ## early stopping\n",
    "    n_fold += 1\n",
    "    early_stopping = EarlyStopping(patience=7,\n",
    "                                     verbose=False,\n",
    "                                     path=save_path,\n",
    "                                     n_fold=n_fold) ## 7번의 에폭후에도 valid loss가 작아지지 않으면 조기 중단\n",
    "    \n",
    "    ## CNN 모델\n",
    "    net = CNN3D()\n",
    "    net.apply(init_weights) ## Linear layer 가중치 초기화\n",
    "    \n",
    "    ## Dataset, Dataloader\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    valid_dataset = TensorDataset(X_valid, y_valid)\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    train_total_batch = len(train_dataloader) ## 배치 크기\n",
    "    valid_total_batch = len(valid_dataloader)\n",
    "    \n",
    "    ## optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate) ## 옵티마이저에 최적화할 파라미터와 학습률 전달\n",
    "    \n",
    "    ## scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                                lr_lambda=lambda epoch: 0.95 ** epoch,\n",
    "                                                last_epoch=-1,\n",
    "                                                verbose=False)\n",
    "    \n",
    "    ## fold별로 모델 학습\n",
    "    net.train() ## 훈련모드\n",
    "    for epoch in range(epochs): ## (배치사이즈 * 에폭)만큼 훈련시킴\n",
    "        train_avg_loss, valid_avg_loss, valid_avg_acc = 0, 0, 0 ## 에폭별 배치단위 평균 훈련 오차와 평균 평가 오차와 valid accuracy\n",
    "\n",
    "        for X, y in train_dataloader: ## 미니 배치 단위로 꺼내온다, X는 미니 배치, y는 레이블\n",
    "            optimizer.zero_grad() ## 그래디언트 초기화\n",
    "            yhat = net(X) ## y_hat을 구한다\n",
    "            loss = loss_fn(yhat, y) ## 오차를 계산 ## train loss\n",
    "            loss.backward()  ## 미분\n",
    "            optimizer.step() ## 업데이트\n",
    "            train_avg_loss += (loss / train_total_batch) ## 각 배치마다 훈련 오차 누적\n",
    "    \n",
    "        ## epoch마다 학습률 조절\n",
    "        scheduler.step()\n",
    "    \n",
    "        ## epoch마다 모델 평가\n",
    "        net.eval() ## 평가모드\n",
    "        for X, y in valid_dataloader: \n",
    "            with torch.no_grad(): ## 평가할 땐 역전파를 쓸 필요가 없으니까\n",
    "                yhat = net(X)\n",
    "                loss = loss_fn(yhat, y) ## valid loss\n",
    "                acc = accuracy(y.detach().numpy(), yhat.detach().numpy().argmax(-1))       \n",
    "                valid_avg_acc += (acc * len(y) / len(valid_dataset)) ## 각 배치마다 정확도(정답 개수 / 전체 개수)\n",
    "                valid_avg_loss += loss / valid_total_batch ## 각 배치마다 평가 오차 누적                                                                  \n",
    "\n",
    "        if epoch % 20 == 0 or epoch == epochs - 1: \n",
    "            ## 20의 배수값을 가지는 에폭마다 평균 배치 훈련 오차와 평가 오차 출력\n",
    "            print('[Epoch: {:>3}] train loss = {:>.5}  valid loss = {:>.5}'.format(epoch + 1, train_avg_loss, valid_avg_loss)) \n",
    "            \n",
    "        ## epoch마다 early stopping 실행\n",
    "        early_stopping(valid_avg_loss, valid_avg_acc, net) ## __call__ function\n",
    "        if early_stopping.early_stop: ## early_stop이 true이면\n",
    "            if epoch % 20 != 0 and epoch != epochs - 1:\n",
    "                print('[Epoch: {:>3}] train loss = {:>.5}  valid loss = {:>.5}'.format(epoch + 1, train_avg_loss, valid_avg_loss)) \n",
    "            print('Early stopping!')\n",
    "            break \n",
    "\n",
    "    cnn_acc.append(early_stopping.val_acc) ## fold별 loss가 가장 작은 모델의 정확도\n",
    "    cnn_loss.append(early_stopping.val_loss_min) ## fold별 loss가 가장 작은 모델의 손실\n",
    "    \n",
    "    ## fold별 평가 루프 종료시 가장 작은 loss와 이때의 accuracy를 출력\n",
    "    print(f'{i + 1} Fold -> Best Valid Loss: {early_stopping.val_loss_min:.5f}  Best Valid Accuracy: {early_stopping.val_acc:.5f}\\n\\n')\n",
    "    \n",
    "## 폴드별 가장 loss가 작은 모델들의 평균 정확도와 평균 손실\n",
    "print(f'{skfold.n_splits}Fold Mean Valid Accuracy: {np.mean(cnn_acc):.5f}')\n",
    "print(f'{skfold.n_splits}Fold Mean Valid Loss: {np.mean(cnn_loss):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6197a2-441a-4b84-8b1f-ed53efc57438",
   "metadata": {},
   "source": [
    "`-` softmax function을 취하면 4개의 원소 중 최대값의 인덱스 번호가 최종 예측값이 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "610b5bcd-dee8-4840-a6a2-409d40f20007",
   "metadata": {},
   "outputs": [],
   "source": [
    "weigh_path_list = glob(save_path + '/*.pt') ## *는 액셀에서의 *의미와 같다(임의 길이의 모든 문자열)\n",
    "cnn_pred = torch.tensor(np.zeros((X_test.shape[0], 4))) ## test예측값\n",
    "\n",
    "for weight in weigh_path_list :\n",
    "    net.load_state_dict(torch.load(weight))\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = net(X_test) ## shape -> (9343, 4)\n",
    "        cnn_pred += outputs / 14  \n",
    "        \n",
    "_, pred = torch.max(cnn_pred, dim=1) ## 최대값과 인덱스를 반환\n",
    "## return (value, indices), 1차원을 기준으로 max를 구한다\n",
    "## 1차원을 기준으로 max를 구하므로 1차원을 없앤 9343개의 max가 반환된다\n",
    "## 행별로 4개의 값 중 최대값을 리턴(총 9343개)\n",
    "## 만약 dim=0으로 했다면 0번째 열~4번째 열별로 최대값을 구하므로 총 4개의 max값이 리턴됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3b7d0119-1fc3-4f73-929d-49c0de7a46f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('C:/Users/Jaesu/Dacon-Basic/손동작-분류/Data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "592f0dc9-913d-468f-ace8-0f26ce968718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   1       0\n",
       "1   2       0\n",
       "2   3       1\n",
       "3   4       3\n",
       "4   5       2"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['target'] = pred\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "53bd0427-9e39-48d5-b00a-47d9f99aae45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    2339\n",
       "1    2385\n",
       "2    2412\n",
       "3    2207\n",
       "dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.groupby('target').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "67096418-f7fb-4794-ac46-4dd25e52fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('C:/Users/Jaesu/github_desktop/Dacon-Basic/손동작-분류/Data/submission2_3d.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c7741-30c1-47a1-9584-d71d5c872b73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
